{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xTIoGiMZe92"
   },
   "outputs": [],
   "source": [
    "# !pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVnAGh2HZe95"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Define templates for each emotion\n",
    "templates = {\n",
    "    'sadness': [\n",
    "        \"I can't believe {}.\",\n",
    "        \"This is the worst {}.\",\n",
    "        \"I feel so {}.\",\n",
    "        \"Nothing seems to {}.\",\n",
    "        \"I'm heartbroken {}.\"\n",
    "    ],\n",
    "    'anger': [\n",
    "        \"I can't stand {}!\",\n",
    "        \"This is absolutely {}!\",\n",
    "        \"I'm furious about {}.\",\n",
    "        \"Why does {} always happen?\",\n",
    "        \"I'm so mad I could {}!\"\n",
    "    ],\n",
    "    'love': [\n",
    "        \"You mean {} to me.\",\n",
    "        \"I cherish every {} with you.\",\n",
    "        \"My heart is full of {} for you.\",\n",
    "        \"I can't imagine {} without you.\",\n",
    "        \"You make everything {}.\"\n",
    "    ],\n",
    "    'surprise': [\n",
    "        \"I didn't see {} coming!\",\n",
    "        \"Wow, what a {}!\",\n",
    "        \"I'm completely {}!\",\n",
    "        \"This is such an {} turn of events.\",\n",
    "        \"I never would have {}!\"\n",
    "    ],\n",
    "    'fear': [\n",
    "        \"I'm really scared {}.\",\n",
    "        \"What if {} happens?\",\n",
    "        \"I can't shake this feeling of {}.\",\n",
    "        \"This situation makes me very {}.\",\n",
    "        \"I'm terrified of {}.\"\n",
    "    ],\n",
    "    'happy': [\n",
    "        \"This is the best {} ever!\",\n",
    "        \"I feel so {} and content.\",\n",
    "        \"I'm incredibly {} right now.\",\n",
    "        \"Everything is {}!\",\n",
    "        \"I can't stop {}!\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Define keywords for each emotion\n",
    "keywords = {\n",
    "    'sadness': ['it\\'s over', 'day of my life', 'alone', 'go right', 'beyond words'],\n",
    "    'anger': ['this', 'unacceptable', 'what happened', 'this', 'scream'],\n",
    "    'love': ['the world', 'moment', 'love', 'life', 'better'],\n",
    "    'surprise': ['that', 'surprise', 'stunned', 'unexpected', 'guessed'],\n",
    "    'fear': ['right now', 'something bad', 'dread', 'uneasy', 'what\\'s to come'],\n",
    "    'happy': ['day', 'joyful', 'happy', 'perfect', 'smiling']\n",
    "}\n",
    "\n",
    "def generate_sentence(emotion):\n",
    "    template = random.choice(templates[emotion])\n",
    "    keyword = random.choice(keywords[emotion])\n",
    "    sentence = template.format(keyword)\n",
    "    return sentence\n",
    "\n",
    "def generate_rule_based_synthetic_data(num_samples):\n",
    "    synthetic_data = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly select an emotion\n",
    "        emotion = random.choice(list(templates.keys()))\n",
    "\n",
    "        # Generate a meaningful sentence for the selected emotion\n",
    "        text = generate_sentence(emotion)\n",
    "\n",
    "        # Append the record to the synthetic data list\n",
    "        synthetic_data.append([text, emotion])\n",
    "\n",
    "    # Create a DataFrame\n",
    "    synthetic_df = pd.DataFrame(synthetic_data, columns=['Text', 'Emotion'])\n",
    "\n",
    "    return synthetic_df\n",
    "\n",
    "# Generate a synthetic dataset with the same number of entries as the original dataset\n",
    "rule_based_synthetic_dataset = generate_rule_based_synthetic_data(21459)\n",
    "\n",
    "## Save the rule-based synthetic dataset to a CSV file\n",
    "rule_based_synthetic_dataset.to_csv('synthetic_dataset.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the synthetic dataset\n",
    "rule_based_synthetic_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_OvmfkrZe97",
    "outputId": "51328131-906d-4dc3-c90e-5ee4fa0957e1"
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install torch pandas scikit-learn torchtext matplotlib\n",
    "\n",
    "!pip install syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qEMZjY1bZe98",
    "outputId": "7d5c801d-64ed-4bd1-d257-4f18b70d9c7d"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Emotion_final.csv dataset\n",
    "emotion_data = pd.read_csv('Emotion_final.csv')\n",
    "\n",
    "# Clean the text in the emotion data\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespaces\n",
    "    return text\n",
    "\n",
    "emotion_data['Text'] = emotion_data['Text'].apply(clean_text)\n",
    "\n",
    "# Load synthetic_data.csv dataset\n",
    "synthetic_data = pd.read_csv('synthetic_dataset.csv')\n",
    "\n",
    "# Clean the text in the synthetic data\n",
    "synthetic_data['Text'] = synthetic_data['Text'].apply(clean_text)\n",
    "\n",
    "# Concatenate the original and synthetic datasets\n",
    "combined_data = pd.concat([emotion_data, synthetic_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Hyperparameters\n",
    "num_clients = 3\n",
    "epochs = 20\n",
    "learning_rate = 1e-5\n",
    "epsilon = 1.0\n",
    "subset_size = 500\n",
    "batch_size = 16\n",
    "\n",
    "# Federated Learning - Split data for each client\n",
    "clients_data = []\n",
    "for _ in range(num_clients):\n",
    "    client_data = combined_data.sample(frac=0.2, random_state=42).reset_index(drop=True).head(subset_size)\n",
    "    clients_data.append(client_data)\n",
    "\n",
    "# Encoding the labels\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(num_clients):\n",
    "    clients_data[i]['Emotion'] = label_encoder.fit_transform(clients_data[i]['Emotion'])\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts.tolist()\n",
    "        self.labels = labels.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = int(self.labels[idx])  # Ensure label is converted to int\n",
    "        encoding = self.tokenizer(text, add_special_tokens=True, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)  # Ensure label is numeric\n",
    "        }\n",
    "\n",
    "# Train each client locally\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "models = []\n",
    "scaler = GradScaler()\n",
    "train_loss_history = [[] for _ in range(num_clients)]\n",
    "train_acc_history = [[] for _ in range(num_clients)]\n",
    "\n",
    "for i in range(num_clients):\n",
    "    client_data = clients_data[i]\n",
    "    train_texts, test_texts, train_labels, test_labels = train_test_split(client_data['Text'], client_data['Emotion'], test_size=0.2, random_state=42)\n",
    "    assert len(train_texts) > 0 and len(test_texts) > 0, \"Train-test split resulted in empty sets\"\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_)).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        train_loss_history[i].append(avg_loss)\n",
    "        train_acc_history[i].append(accuracy)\n",
    "        print(f\"Client {i}, Epoch {epoch + 1}, Loss: {avg_loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "# Aggregation Step\n",
    "# Combine the weights of the models for global model\n",
    "global_state_dict = {}\n",
    "for key in models[0].state_dict().keys():\n",
    "    global_state_dict[key] = sum(model.state_dict()[key] for model in models) / num_clients\n",
    "\n",
    "# Update the global model with the aggregated weights\n",
    "global_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_)).to(device)\n",
    "global_model.load_state_dict(global_state_dict)\n",
    "\n",
    "# Evaluate the global model on both original and synthetic test sets together\n",
    "original_test_texts = emotion_data['Text']\n",
    "original_test_labels = label_encoder.transform(emotion_data['Emotion'])\n",
    "original_test_dataset = TextDataset(original_test_texts, original_test_labels, tokenizer)\n",
    "original_test_loader = DataLoader(original_test_dataset, batch_size=batch_size)\n",
    "\n",
    "synthetic_test_texts = synthetic_data['Text']\n",
    "synthetic_test_labels = label_encoder.transform(synthetic_data['Emotion'])\n",
    "synthetic_test_dataset = TextDataset(synthetic_test_texts, synthetic_test_labels, tokenizer)\n",
    "synthetic_test_loader = DataLoader(synthetic_test_dataset, batch_size=batch_size)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch1, batch2 in zip(original_test_loader, synthetic_test_loader):\n",
    "        input_ids1 = batch1['input_ids'].to(device)\n",
    "        attention_mask1 = batch1['attention_mask'].to(device)\n",
    "        labels1 = batch1['labels'].to(device)\n",
    "\n",
    "        input_ids2 = batch2['input_ids'].to(device)\n",
    "        attention_mask2 = batch2['attention_mask'].to(device)\n",
    "        labels2 = batch2['labels'].to(device)\n",
    "\n",
    "        outputs1 = global_model(input_ids1, attention_mask=attention_mask1)\n",
    "        _, predicted1 = torch.max(outputs1.logits, dim=1)\n",
    "        total += labels1.size(0)\n",
    "        correct += (predicted1 == labels1).sum().item()\n",
    "\n",
    "        outputs2 = global_model(input_ids2, attention_mask=attention_mask2)\n",
    "        _, predicted2 = torch.max(outputs2.logits, dim=1)\n",
    "        total += labels2.size(0)\n",
    "        correct += (predicted2 == labels2).sum().item()\n",
    "\n",
    "overall_test_accuracy = correct / total\n",
    "print(f\"Overall Test Accuracy on both original and synthetic test sets: {overall_test_accuracy:.4f}\")\n",
    "\n",
    "# Plot the training loss and accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(num_clients):\n",
    "    plt.subplot(2, num_clients, i+1)\n",
    "    plt.plot(range(epochs), train_loss_history[i], label=f'Client {i} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Client {i} Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, num_clients, num_clients+i+1)\n",
    "    plt.plot(range(epochs), train_acc_history[i], label=f'Client {i} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Client {i} Training Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate overall epsilon value\n",
    "epsilon_values = [epsilon / num_clients] * num_clients\n",
    "overall_epsilon = sum(epsilon_values)\n",
    "print(f\"Overall epsilon value: {overall_epsilon}\")\n",
    "\n",
    "# Forecast emotions for the test dataset (simulating future dataset)\n",
    "def forecast(model, tokenizer, dataset, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits, dim=1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Simulated future dataset (for demonstration, we will use a random sample from the combined data)\n",
    "simulated_future_texts = combined_data.sample(frac=0.1, random_state=42)['Text']\n",
    "simulated_future_labels = label_encoder.transform(combined_data.sample(frac=0.1, random_state=42)['Emotion'])\n",
    "simulated_future_dataset = TextDataset(simulated_future_texts, simulated_future_labels, tokenizer)\n",
    "\n",
    "# Forecast emotions for the simulated future dataset\n",
    "predictions = forecast(global_model, tokenizer, simulated_future_dataset, device)\n",
    "predicted_emotions = label_encoder.inverse_transform(predictions)\n",
    "print(\"Predicted Emotions for Simulated Test Dataset:\", predicted_emotions)\n",
    "\n",
    "# Evaluate performance on the simulated test dataset with ground truth\n",
    "test_true_emotions = label_encoder.inverse_transform(simulated_future_labels)\n",
    "accuracy = np.mean(predicted_emotions == test_true_emotions)\n",
    "precision = precision_score(test_true_emotions, predicted_emotions, average='weighted')\n",
    "recall = recall_score(test_true_emotions, predicted_emotions, average='weighted')\n",
    "f1 = f1_score(test_true_emotions, predicted_emotions, average='weighted')\n",
    "cm = confusion_matrix(test_true_emotions, predicted_emotions)\n",
    "\n",
    "print(f\"Forecast Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Forecast Test Precision: {precision:.4f}\")\n",
    "print(f\"Forecast Test Recall: {recall:.4f}\")\n",
    "print(f\"Forecast Test F1 Score: {f1:.4f}\")\n",
    "print(\"Forecast Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyXrobojZe99"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the datasets\n",
    "original_data_path = 'Emotion_final.csv'\n",
    "# obfuscated_data_path = 'synthetic_dataset.csv'\n",
    "\n",
    "# Load the datasets into pandas DataFrames\n",
    "original_data = pd.read_csv(original_data_path)\n",
    "obfuscated_data = combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvj_ujE3Ze99",
    "outputId": "b2758d85-cbf0-456a-c48d-43ce33f1d10d"
   },
   "outputs": [],
   "source": [
    "##Membership Inference Attack is performed on the global model\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def membership_inference_attack(global_model, original_data, synthetic_data, tokenizer, device):\n",
    "    global_model.eval()\n",
    "\n",
    "    def get_max_prob(data, labels):\n",
    "        max_probs = []\n",
    "        for text, label in zip(data, labels):\n",
    "            encoding = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = global_model(**{k: v.to(device) for k, v in encoding.items()})\n",
    "                probs = torch.softmax(outputs.logits, dim=1)\n",
    "                max_probs.append(probs.max().item())\n",
    "        return np.array(max_probs)\n",
    "\n",
    "    original_max_probs = get_max_prob(original_data['Text'], original_data['Emotion'])\n",
    "    synthetic_max_probs = get_max_prob(synthetic_data['Text'], synthetic_data['Emotion'])\n",
    "\n",
    "    labels = np.concatenate([np.ones(len(original_max_probs)), np.zeros(len(synthetic_max_probs))])\n",
    "    scores = np.concatenate([original_max_probs, synthetic_max_probs])\n",
    "\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    print(f\"Membership Inference Attack AUC: {auc:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "membership_inference_attack(global_model, emotion_data, synthetic_data, tokenizer, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVeGecUwZe9-",
    "outputId": "17d6a76e-a8b4-4252-ada0-9ccb47f7b70f"
   },
   "outputs": [],
   "source": [
    "##Membership Inference Attack is performed on the Local model scenario\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def membership_inference_attack(global_model, member_data, non_member_data, tokenizer, device):\n",
    "    global_model.eval()\n",
    "\n",
    "    def get_max_prob(data, tokenizer, device):\n",
    "        max_probs = []\n",
    "        for text in data:\n",
    "            encoding = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "                outputs = global_model(**encoding)\n",
    "                probs = torch.softmax(outputs.logits, dim=1)\n",
    "                max_probs.append(probs.max().item())\n",
    "        return np.array(max_probs)\n",
    "\n",
    "    # Get maximum probabilities for member (training) and non-member (testing) data\n",
    "    member_max_probs = get_max_prob(member_data['Text'], tokenizer, device)\n",
    "    non_member_max_probs = get_max_prob(non_member_data['Text'], tokenizer, device)\n",
    "\n",
    "    # Create labels: 1 for members (training data) and 0 for non-members (testing data)\n",
    "    labels = np.concatenate([np.ones(len(member_max_probs)), np.zeros(len(non_member_max_probs))])\n",
    "\n",
    "    # Combine the scores from both sets\n",
    "    scores = np.concatenate([member_max_probs, non_member_max_probs])\n",
    "\n",
    "    # Calculate AUC to evaluate the attack's performance\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    print(f\"Membership Inference Attack AUC: {auc:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Simulating members as part of the training data and non-members as part of the test data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(emotion_data['Text'], emotion_data['Emotion'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the split data into pandas DataFrames\n",
    "member_data = pd.DataFrame({'Text': train_texts, 'Emotion': train_labels})\n",
    "non_member_data = pd.DataFrame({'Text': test_texts, 'Emotion': test_labels})\n",
    "\n",
    "# Perform the membership inference attack\n",
    "membership_inference_attack(global_model, member_data, non_member_data, tokenizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0r-GzAOZe9-",
    "outputId": "bfec7547-07a8-4f04-8d61-3882e3251a88"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Function to generate linkage attack data for local models\n",
    "def generate_linkage_data(models, clients_data, tokenizer, device):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, client_data in enumerate(clients_data):\n",
    "        # Convert the client's text and labels to dataset\n",
    "        dataset = TextDataset(client_data['Text'], client_data['Emotion'], tokenizer)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        client_predictions = []\n",
    "        client_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                outputs = models[i](input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "                client_predictions.extend(probabilities.cpu().numpy())\n",
    "                client_labels.extend([i] * len(probabilities))  # Assign the client's index as the label\n",
    "\n",
    "        all_predictions.extend(client_predictions)\n",
    "        all_labels.extend(client_labels)\n",
    "\n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "# Generate linkage attack data\n",
    "all_predictions, all_labels = generate_linkage_data(models, clients_data, tokenizer, device)\n",
    "\n",
    "# Convert labels to one-hot encoding for AUC calculation\n",
    "all_labels_one_hot = label_binarize(all_labels, classes=list(range(num_clients)))\n",
    "\n",
    "# Calculate AUC for each client\n",
    "auc_scores = []\n",
    "for i in range(num_clients):\n",
    "    # Calculate AUC for the current client (one-vs-rest)\n",
    "    auc = roc_auc_score(all_labels_one_hot[:, i], all_predictions[:, i])\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"AUC for Client {i}: {auc:.4f}\")\n",
    "\n",
    "# Calculate macro-average AUC (average AUC across all clients)\n",
    "macro_auc = np.mean(auc_scores)\n",
    "print(f\"Macro-Average AUC: {macro_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 981611,
     "sourceId": 1658104,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5190210,
     "sourceId": 8662398,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
