{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utRCgzR_Ppcl",
    "outputId": "39fd7043-76c8-409c-ab4c-c00ebd11ee27"
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install torch pandas scikit-learn torchtext opacus gensim matplotlib\n",
    "\n",
    "# Verify GPU availability\n",
    "import torch\n",
    "print(\"GPU available: \", torch.cuda.is_available())\n",
    "print(\"GPU name: \", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAAJtNt-PskM",
    "outputId": "c897276e-2cea-4f30-bf8e-1a59d7d2d2ad"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Smq6rB8Psng",
    "outputId": "4384d003-d5eb-43a6-8ccc-f8efed9f484e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from opacus import PrivacyEngine\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load and prepare the dataset\n",
    "df = pd.read_csv('Emotion_final.csv')\n",
    "\n",
    "# Data cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply data cleaning\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Emotion'] = label_encoder.fit_transform(df['Emotion'])\n",
    "\n",
    "# Tokenization and Vocabulary Creation with pre-trained FastText embeddings\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "def get_vector(token):\n",
    "    try:\n",
    "        return torch.tensor(fasttext_model[token])\n",
    "    except KeyError:\n",
    "        return torch.zeros(fasttext_model.vector_size)\n",
    "\n",
    "counter = Counter()\n",
    "for line in df['Text']:\n",
    "    counter.update(tokenizer(line))\n",
    "\n",
    "vocab = build_vocab_from_iterator([counter.keys()], specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Manually map the FastText vectors to the vocabulary\n",
    "vectors = []\n",
    "for token in vocab.get_itos():\n",
    "    vectors.append(get_vector(token))\n",
    "vocab.vectors = torch.stack(vectors)\n",
    "\n",
    "def tokenize_and_pad(text_iter, tokenizer, vocab, max_length=50):\n",
    "    tokenized_texts = [torch.tensor([vocab[token] for token in tokenizer(item)], dtype=torch.long) for item in text_iter]\n",
    "    padded_texts = torch.zeros((len(tokenized_texts), max_length), dtype=torch.long)\n",
    "    for i, t in enumerate(tokenized_texts):\n",
    "        length = min(len(t), max_length)\n",
    "        padded_texts[i, :length] = t[:length]\n",
    "    return padded_texts\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Emotion'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare data\n",
    "train_data = tokenize_and_pad(X_train.tolist(), tokenizer, vocab)\n",
    "test_data = tokenize_and_pad(X_test.tolist(), tokenizer, vocab)\n",
    "train_labels = torch.tensor(y_train.values).long()\n",
    "test_labels = torch.tensor(y_test.values).long()\n",
    "\n",
    "# Define the Dataset class\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Manually split the dataset for federated clients\n",
    "num_clients = 5\n",
    "client_data_size = len(train_data) // num_clients\n",
    "client_datasets = []\n",
    "\n",
    "start = 0\n",
    "for i in range(num_clients):\n",
    "    end = start + client_data_size if i < num_clients - 1 else len(train_data)\n",
    "    client_texts = train_data[start:end]\n",
    "    client_labels = train_labels[start:end]\n",
    "    client_datasets.append(CustomTextDataset(client_texts, client_labels))\n",
    "    start = end\n",
    "\n",
    "# Model Definition with Dropout and Increased LSTM Layers\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embedding.weight.data.copy_(vocab.vectors)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=3, batch_first=True, dropout=0.3)  # Changed to LSTM with dropout\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        hidden = lstm_out[:, -1, :]\n",
    "        return self.fc(hidden)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_model = SentimentAnalysisModel(len(vocab), 300, 256, len(label_encoder.classes_)).to(device)\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = total_correct / total_samples\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def federated_train(model, client_datasets, epochs, device, apply_ldp=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    privacy_metrics = []\n",
    "    privacy_engine = PrivacyEngine(accountant=\"rdp\")  # Use the new API\n",
    "    for epoch in range(epochs):\n",
    "        local_weights = []\n",
    "        for client_data in client_datasets:\n",
    "            local_model = SentimentAnalysisModel(len(vocab), 300, 256, len(label_encoder.classes_)).to(device)\n",
    "            local_model.load_state_dict(model.state_dict())  # Start with global model weights\n",
    "            optimizer = optim.Adam(local_model.parameters(), lr=0.001)\n",
    "            data_loader = DataLoader(client_data, batch_size=32, shuffle=True)\n",
    "\n",
    "            # Initialize PrivacyEngine\n",
    "            local_model, optimizer, data_loader = privacy_engine.make_private(\n",
    "                module=local_model,\n",
    "                optimizer=optimizer,\n",
    "                data_loader=data_loader,\n",
    "                noise_multiplier=0.1,  # Reduce noise\n",
    "                max_grad_norm=1.0\n",
    "            )\n",
    "\n",
    "            # Training loop\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = local_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Apply Local Differential Privacy (LDP) by adding noise to the local model updates before sending them to the server\n",
    "            if apply_ldp:\n",
    "                for param in local_model.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        param.grad += torch.normal(mean=0, std=0.1, size=param.grad.shape).to(device)\n",
    "\n",
    "            # Adjust keys in the state_dict and gather the local weights\n",
    "            adjusted_state_dict = {key.replace('_module.', ''): value for key, value in local_model.state_dict().items()}\n",
    "            local_weights.append(adjusted_state_dict)\n",
    "\n",
    "        # Aggregate weights and add noise for Central Differential Privacy (CDP)\n",
    "        global_weights = {k: torch.mean(torch.stack([w[k] for w in local_weights]), 0) for k in local_weights[0].keys()}\n",
    "        for k, v in global_weights.items():\n",
    "            global_weights[k] += torch.normal(mean=0, std=0.1, size=v.shape).to(device)  # CDP noise\n",
    "\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "        # Log privacy metrics\n",
    "        epsilon, best_alpha = privacy_engine.accountant.get_privacy_spent(delta=1e-5)\n",
    "        privacy_metrics.append((epsilon, best_alpha))\n",
    "        print(f'Epoch {epoch+1} completed: (ε = {epsilon:.2f}, best α = {best_alpha})')\n",
    "\n",
    "    return privacy_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r3Ypv_7nPsqy",
    "outputId": "d0d0a978-f3fb-4b42-d89b-22573308a8bd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.layers import DPLSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "# Load and prepare the dataset\n",
    "df = pd.read_csv('Emotion_final.csv')\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Emotion'] = label_encoder.fit_transform(df['Emotion'])\n",
    "\n",
    "# Tokenization and Vocabulary Creation with pre-trained FastText embeddings\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "def get_vector(token):\n",
    "    try:\n",
    "        return torch.tensor(fasttext_model[token])\n",
    "    except KeyError:\n",
    "        return torch.zeros(fasttext_model.vector_size)\n",
    "\n",
    "counter = Counter()\n",
    "for line in df['Text']:\n",
    "    counter.update(tokenizer(line))\n",
    "\n",
    "vocab = build_vocab_from_iterator([counter.keys()], specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Manually map the FastText vectors to the vocabulary\n",
    "vectors = []\n",
    "for token in vocab.get_itos():\n",
    "    vectors.append(get_vector(token))\n",
    "vocab.vectors = torch.stack(vectors)\n",
    "\n",
    "def tokenize_and_pad(text_iter, tokenizer, vocab):\n",
    "    tokenized_texts = [torch.tensor([vocab[token] for token in tokenizer(item)], dtype=torch.long) for item in text_iter]\n",
    "    max_length = max(len(t) for t in tokenized_texts)\n",
    "    padded_texts = torch.zeros((len(tokenized_texts), max_length), dtype=torch.long)\n",
    "    for i, t in enumerate(tokenized_texts):\n",
    "        padded_texts[i, :len(t)] = t\n",
    "    return padded_texts\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Emotion'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare data\n",
    "train_data = tokenize_and_pad(X_train.tolist(), tokenizer, vocab)\n",
    "test_data = tokenize_and_pad(X_test.tolist(), tokenizer, vocab)\n",
    "train_labels = torch.tensor(y_train.values).long()\n",
    "test_labels = torch.tensor(y_test.values).long()\n",
    "\n",
    "# Define the Dataset class\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Manually split the dataset for federated clients\n",
    "num_clients = 5\n",
    "client_data_size = len(train_data) // num_clients\n",
    "client_datasets = []\n",
    "\n",
    "start = 0\n",
    "for i in range(num_clients):\n",
    "    end = start + client_data_size if i < num_clients - 1 else len(train_data)\n",
    "    client_texts = train_data[start:end]\n",
    "    client_labels = train_labels[start:end]\n",
    "    client_datasets.append(CustomTextDataset(client_texts, client_labels))\n",
    "    start = end\n",
    "\n",
    "# Model Definition with Dropout and Increased LSTM Layers\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embedding.weight.data.copy_(vocab.vectors)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = DPLSTM(embed_dim, hidden_dim, num_layers=3, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        hidden = self.dropout(lstm_out[:, -1, :])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_model = SentimentAnalysisModel(len(vocab), 300, 256, len(label_encoder.classes_)).to(device)\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = total_correct / total_samples\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def federated_train(model, client_datasets, epochs, device, apply_ldp=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    privacy_metrics = []\n",
    "    privacy_engine = PrivacyEngine(accountant=\"rdp\")  # Use the new API\n",
    "    for epoch in range(epochs):\n",
    "        local_weights = []\n",
    "        for client_data in client_datasets:\n",
    "            local_model = SentimentAnalysisModel(len(vocab), 300, 256, len(label_encoder.classes_)).to(device)\n",
    "            local_model.load_state_dict(model.state_dict())  # Start with global model weights\n",
    "            optimizer = optim.Adam(local_model.parameters(), lr=0.001)\n",
    "            data_loader = DataLoader(client_data, batch_size=32, shuffle=True)\n",
    "\n",
    "            # Initialize PrivacyEngine\n",
    "            local_model, optimizer, data_loader = privacy_engine.make_private(\n",
    "                module=local_model,\n",
    "                optimizer=optimizer,\n",
    "                data_loader=data_loader,\n",
    "                noise_multiplier=0.1,  # Reduce noise\n",
    "                max_grad_norm=1.0\n",
    "            )\n",
    "\n",
    "            # Training loop\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = local_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Apply Local Differential Privacy (LDP) by adding noise to the local model updates before sending them to the server\n",
    "            if apply_ldp:\n",
    "                for param in local_model.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        param.grad += torch.normal(mean=0, std=0.1, size=param.grad.shape).to(device)\n",
    "\n",
    "            # Adjust keys in the state_dict and gather the local weights\n",
    "            adjusted_state_dict = {key.replace('_module.', ''): value for key, value in local_model.state_dict().items()}\n",
    "            local_weights.append(adjusted_state_dict)\n",
    "\n",
    "        # Aggregate weights and add noise for Central Differential Privacy (CDP)\n",
    "        global_weights = {k: torch.mean(torch.stack([w[k] for w in local_weights]), 0) for k in local_weights[0].keys()}\n",
    "        for k, v in global_weights.items():\n",
    "            global_weights[k] += torch.normal(mean=0, std=0.1, size=v.shape).to(device)  # CDP noise\n",
    "\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "        # Log privacy metrics\n",
    "        epsilon, best_alpha = privacy_engine.accountant.get_privacy_spent(delta=1e-5)\n",
    "        privacy_metrics.append((epsilon, best_alpha))\n",
    "        print(f'Epoch {epoch+1} completed: (ε = {epsilon:.2f}, best α = {best_alpha})')\n",
    "\n",
    "    return privacy_metrics\n",
    "\n",
    "# Train and evaluate the model\n",
    "privacy_metrics = federated_train(global_model, client_datasets, 20, device, apply_ldp=True)  # Increase the number of epochs and apply LDP\n",
    "test_dataset = CustomTextDataset(test_data, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "accuracy, precision, recall, f1 = evaluate(global_model, test_dataloader, device)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Plot Privacy vs Utility\n",
    "epochs = range(1, 21)\n",
    "epsilons = [metrics[0] for metrics in privacy_metrics]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, epsilons, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Epsilon (ε)')\n",
    "plt.title('Privacy (Epsilon) over Epochs')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
